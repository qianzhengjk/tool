{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "1  0.502517       NaN  1.072976 -0.590623\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "4  0.258106  0.946007 -1.145129       NaN\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n",
      "    col1   col2   col3   col4\n",
      "0  False  False  False  False\n",
      "1  False   True  False  False\n",
      "2  False  False  False  False\n",
      "3  False  False  False  False\n",
      "4  False  False  False   True\n",
      "5  False  False  False  False\n",
      "col1    False\n",
      "col2     True\n",
      "col3    False\n",
      "col4     True\n",
      "dtype: bool\n",
      "col1    False\n",
      "col2    False\n",
      "col3    False\n",
      "col4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # 导入pandas库\n",
    "import numpy as np  # 导入numpy库\n",
    "from sklearn.preprocessing import Imputer  # 导入sklearn.preprocessing中的Imputer库\n",
    "\n",
    "# 生成缺失数据\n",
    "df = pd.DataFrame(np.random.randn(6, 4), columns=['col1', 'col2', 'col3', 'col4'])  # 生成一份数据\n",
    "df.iloc[1:2, 1] = np.nan  # 增加缺失值\n",
    "df.iloc[4, 3] = np.nan  # 增加缺失值\n",
    "print (df)\n",
    "\n",
    "# 查看哪些值缺失\n",
    "nan_all = df.isnull()  # 获得所有数据框中的N值\n",
    "print (nan_all)  # 打印输出\n",
    "\n",
    "# 查看哪些列缺失\n",
    "nan_col1 = df.isnull().any()  # 获得含有NA的列\n",
    "nan_col2 = df.isnull().all()  # 获得全部为NA的列\n",
    "print (nan_col1)  # 打印输出\n",
    "print (nan_col2)  # 打印输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 丢弃缺失值\n",
    "df2 = df.dropna()  # 直接丢弃含有NA的行记录\n",
    "print (df2)  # 打印输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.43818795 -0.90996192  1.26161039  0.38841426]\n",
      " [ 0.50251733  0.29164428  1.07297616 -0.59062252]\n",
      " [-0.22027851 -0.25489225  1.61212832  0.5231771 ]\n",
      " [ 0.54260647  1.14827047  1.59807087  2.24442568]\n",
      " [ 0.25810586  0.94600708 -1.14512888  0.43370663]\n",
      " [ 2.45386697  0.52879801 -1.65908792 -0.39686138]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn将缺失值替换为特定值\n",
    "nan_model = Imputer(missing_values='NaN', strategy='mean', axis=0)  # 建立替换规则：将值为Nan的缺失值以均值做替换\n",
    "nan_result = nan_model.fit_transform(df)  # 应用模型规则\n",
    "print (nan_result)  # 打印输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "1  0.502517 -0.254892  1.072976 -0.590623\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "4  0.258106  0.946007 -1.145129 -0.396861\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n",
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "1  0.502517 -0.254892  1.072976 -0.590623\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "4  0.258106  0.946007 -1.145129 -0.396861\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n",
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "1  0.502517 -0.909962  1.072976 -0.590623\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "4  0.258106  0.946007 -1.145129  2.244426\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n",
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "1  0.502517  0.000000  1.072976 -0.590623\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "4  0.258106  0.946007 -1.145129  0.000000\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n",
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "1  0.502517  1.100000  1.072976 -0.590623\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "4  0.258106  0.946007 -1.145129  1.200000\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n",
      "       col1      col2      col3      col4\n",
      "0 -1.438188 -0.909962  1.261610  0.388414\n",
      "1  0.502517  0.291644  1.072976 -0.590623\n",
      "2 -0.220279 -0.254892  1.612128  0.523177\n",
      "3  0.542606  1.148270  1.598071  2.244426\n",
      "4  0.258106  0.946007 -1.145129  0.433707\n",
      "5  2.453867  0.528798 -1.659088 -0.396861\n"
     ]
    }
   ],
   "source": [
    "# 使用pandas将缺失值替换为特定值\n",
    "nan_result_pd1 = df.fillna(method='backfill')  # 用后面的值替换缺失值\n",
    "nan_result_pd2 = df.fillna(method='bfill', limit=1)  # 用后面的值替代缺失值,限制每列只能替代一个缺失值\n",
    "nan_result_pd3 = df.fillna(method='pad')  # 用前面的值替换缺失值\n",
    "nan_result_pd4 = df.fillna(0)  # 用0替换缺失值\n",
    "nan_result_pd5 = df.fillna({'col2': 1.1, 'col4': 1.2})  # 用不同值替换不同列的缺失值\n",
    "nan_result_pd6 = df.fillna(df.mean()['col2':'col4'])  # 用平均数代替,选择各自列的均值替换缺失值\n",
    "# 打印输出\n",
    "print (nan_result_pd1)  # 打印输出\n",
    "print (nan_result_pd2)  # 打印输出\n",
    "print (nan_result_pd3)  # 打印输出\n",
    "print (nan_result_pd4)  # 打印输出\n",
    "print (nan_result_pd5)  # 打印输出\n",
    "print (nan_result_pd6)  # 打印输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1    12\n",
      "1   120    17\n",
      "2     3    31\n",
      "3     5    53\n",
      "4     2    22\n",
      "5    12    32\n",
      "6    13    43\n",
      "    col1   col2\n",
      "0  False  False\n",
      "1   True  False\n",
      "2  False  False\n",
      "3  False  False\n",
      "4  False  False\n",
      "5  False  False\n",
      "6  False  False\n"
     ]
    }
   ],
   "source": [
    "## 异常值处理\n",
    "import pandas as pd  # 导入pandas库\n",
    "\n",
    "# 生成异常数据\n",
    "df = pd.DataFrame({'col1': [1, 120, 3, 5, 2, 12, 13],\n",
    "                   'col2': [12, 17, 31, 53, 22, 32, 43]})\n",
    "print (df)  # 打印输出\n",
    "\n",
    "# 通过Z-Score方法判断异常值\n",
    "df_zscore = df.copy()  # 复制一个用来存储Z-score得分的数据框\n",
    "cols = df.columns  # 获得数据框的列名\n",
    "for col in cols:  # 循环读取每列\n",
    "    df_col = df[col]  # 得到每列的值\n",
    "    z_score = (df_col - df_col.mean()) / df_col.std()  # 计算每列的Z-score得分\n",
    "    df_zscore[col] = z_score.abs() > 2.2  # 判断Z-score得分是否大于2.2，如果是则是True，否则为False\n",
    "print (df_zscore)  # 打印输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1  col2\n",
      "0    a     3\n",
      "1    b     2\n",
      "2    a     3\n",
      "3    c     2\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "## 重复值处理\n",
    "import pandas as pd  # 导入pandas库\n",
    "\n",
    "# 生成重复数据\n",
    "data1 = ['a', 3]\n",
    "data2 = ['b', 2]\n",
    "data3 = ['a', 3]\n",
    "data4 = ['c', 2]\n",
    "df = pd.DataFrame([data1, data2, data3, data4], columns=['col1', 'col2'])\n",
    "print (df)\n",
    "\n",
    "# 判断重复数据\n",
    "isDuplicated = df.duplicated()  # 判断重复数据记录\n",
    "print (isDuplicated)  # 打印输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1  col2\n",
      "0    a     3\n",
      "1    b     2\n",
      "3    c     2\n",
      "  col1  col2\n",
      "0    a     3\n",
      "1    b     2\n",
      "3    c     2\n",
      "  col1  col2\n",
      "0    a     3\n",
      "1    b     2\n"
     ]
    }
   ],
   "source": [
    "# 删除重复值\n",
    "new_df1 = df.drop_duplicates()  # 删除数据记录中所有列值相同的记录\n",
    "new_df2 = df.drop_duplicates(['col1'])  # 删除数据记录中col1值相同的记录\n",
    "new_df3 = df.drop_duplicates(['col2'])  # 删除数据记录中col2值相同的记录\n",
    "new_df4 = df.drop_duplicates(['col1', 'col2'])  # 删除数据记录中指定列（col1/col2）值相同的记录\n",
    "print (new_df1)  # 打印输出\n",
    "print (new_df2)  # 打印输出\n",
    "print (new_df3)  # 打印输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id   level     sex\n",
      "0  3566841    high    male\n",
      "1  6541227     low  Female\n",
      "2  3512441  middle  Female\n",
      "        id level_high level_low level_middle sex_male sex_Female\n",
      "0  3566841       True     False        False     True      False\n",
      "1  6541227      False      True        False    False       True\n",
      "2  3512441      False     False         True    False       True\n"
     ]
    }
   ],
   "source": [
    "# 3.2 将分类数据和顺序数据转换为标志变量\n",
    "import pandas as pd  # 导入pandas库\n",
    "from sklearn.preprocessing import OneHotEncoder  # 导入OneHotEncoder库\n",
    "\n",
    "# 生成数据\n",
    "df = pd.DataFrame({'id': [3566841, 6541227, 3512441],\n",
    "                   'sex': ['male', 'Female', 'Female'],\n",
    "                   'level': ['high', 'low', 'middle']})\n",
    "print (df)  # 打印输出原始数据框\n",
    "\n",
    "# 自定义转换主过程\n",
    "df_new = df.copy()  # 复制一份新的数据框用来存储转换结果\n",
    "for col_num, col_name in enumerate(df):  # 循环读出每个列的索引值和列名\n",
    "    col_data = df[col_name]  # 获得每列数据\n",
    "    col_dtype = col_data.dtype  # 获得每列dtype类型\n",
    "    if col_dtype == 'object':  # 如果dtype类型是object（非数值型），执行条件\n",
    "        df_new = df_new.drop(col_name, 1)  # 删除df数据框中要进行标志转换的列\n",
    "        value_sets = col_data.unique()  # 获取分类和顺序变量的唯一值域\n",
    "        for value_unique in value_sets:  # 读取分类和顺序变量中的每个值\n",
    "            col_name_new = col_name + '_' + value_unique  # 创建新的列名，使用原标题+值的方式命名\n",
    "            col_tmp = df.iloc[:, col_num]  # 获取原始数据列\n",
    "            new_col = (col_tmp == value_unique)  # 将原始数据列与每个值进行比较，相同为True，否则为False\n",
    "            df_new[col_name_new] = new_col  # 为最终结果集增加新列值\n",
    "print (df_new)  # 打印输出转换后的数据框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    0    1    2    3    4\n",
      "0  3566841  0.0  0.0  1.0  1.0  0.0\n",
      "1  6541227  1.0  0.0  0.0  0.0  1.0\n",
      "2  3512441  0.0  1.0  0.0  0.0  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn进行标志转换\n",
    "df2 = pd.DataFrame({'id': [3566841, 6541227, 3512441],\n",
    "                    'sex': [1, 2, 2],\n",
    "                    'level': [3, 1, 2]})\n",
    "id_data = df2.values[:, :1]  # 获得ID列\n",
    "transform_data = df2.values[:, 1:]  # 指定要转换的列\n",
    "enc = OneHotEncoder()  # 建立模型对象\n",
    "df2_new = enc.fit_transform(transform_data).toarray()# 标志转换\n",
    "df2_all = pd.concat((pd.DataFrame(id_data), pd.DataFrame(df2_new)), axis=1)  # 组合为数据框\n",
    "print (df2_all)  # 打印输出转换后的数据框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.88622997  1.31785876 -0.16480621  0.56536882 -1.11934542 -0.53218995\n",
      " -0.6843102   1.24149827  1.00579225  0.45485041] 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Administrator\\\\Desktop\\\\')\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 读取数据文件\n",
    "data = np.loadtxt('data1.txt')  # 读取文本数据文件\n",
    "x = data[:, :-1]  # 获得输入的x\n",
    "y = data[:, -1]  # 获得目标变量y\n",
    "print (x[0], y[0])  # 打印输出x和y的第一条记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03331054  0.01513967  0.02199713  0.119727    0.47930312  0.04776297\n",
      "  0.17111746  0.02585441  0.02012725  0.06566044]\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn的DecisionTreeClassifier判断变量重要性\n",
    "model_tree = DecisionTreeClassifier(random_state=0)  # 建立分类决策树模型对象\n",
    "model_tree.fit(x, y)  # 将数据集的维度和目标变量输入模型\n",
    "feature_importance = model_tree.feature_importances_  # 获得所有变量的重要性得分\n",
    "print (feature_importance)  # 打印输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.18818316e-03   1.41619205e-02   1.00543847e-02   3.65097575e-01\n",
      "    6.38944537e-01  -1.95750380e-02  -1.73413378e-01  -3.80829974e-02\n",
      "   -2.87413113e-03  -6.52829504e-01]\n",
      " [  1.01307710e-02  -1.95270201e-04  -2.33689543e-02  -6.12915216e-01\n",
      "    5.08983971e-01  -2.23429533e-02   6.02958940e-01  -1.49061329e-02\n",
      "   -1.81362216e-02  -3.41623971e-03]]\n",
      "[ 4.22602937  2.21149972]\n",
      "[  3.38339364e-01   1.77054475e-01   8.92753857e-02   8.73655166e-02\n",
      "   8.23542686e-02   8.03329836e-02   7.38094896e-02   7.14685179e-02\n",
      "   3.14726161e-32   2.98680265e-33]\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn的PCA进行维度转换\n",
    "model_pca = PCA()  # 建立PCA模型对象\n",
    "model_pca.fit(x)  # 将数据集输入模型\n",
    "model_pca.transform(x)  # 对数据集进行转换映射\n",
    "components = model_pca.components_  # 获得转换后的所有主成分\n",
    "components_var = model_pca.explained_variance_  # 获得各主成分的方差\n",
    "components_var_ratio = model_pca.explained_variance_ratio_  # 获得各主成分的方差占比\n",
    "print (components[:2])  # 打印输出前2个主成分\n",
    "print (components_var[:2])  # 打印输出前2个主成分的方差\n",
    "print (components_var_ratio)  # 打印输出所有主成分的方差占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
